{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c13568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import networkx as nx\n",
    "from nltk.tokenize import  sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1625a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Maria Sharapova has basically no friends as te...\n",
       "1    BASEL, Switzerland (AP), Roger Federer advance...\n",
       "2    Roger Federer has revealed that organisers of ...\n",
       "3    Kei Nishikori will try to end his long losing ...\n",
       "4    Federer, 37, first broke through on tour over ...\n",
       "5    Nadal has not played tennis since he was force...\n",
       "6    Tennis giveth, and tennis taketh away. The end...\n",
       "7    Federer won the Swiss Indoors last week by bea...\n",
       "Name: article_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tennis_articles_v4.csv')\n",
    "df['article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2ee696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "s = 'he&&&s'\n",
    "s = re.sub(\"[^a-zA-Z]\",\" \",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f193849",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "s = \"\"\n",
    "for a in df['article_text']:\n",
    "      s += a\n",
    "s = s.lower()\n",
    "\n",
    "sentences = sent_tokenize(s)\n",
    "\n",
    "final = []\n",
    "\n",
    "for s in sentences:\n",
    "      temp = re.sub(\"[^a-zA-Z]\",\" \",s)\n",
    "      temp = temp.lower()\n",
    "      final.append(temp)\n",
    "      dict[temp] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b52a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec594f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_similarity_martix = build_similarity_matrix(final, '')\n",
    "\n",
    "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(final)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8671e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argentina and britain received wild cards to the new-look event, and will compete along with the four 2018 semi-finalists and the 12 teams who win qualifying rounds next february.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "     print(dict[ranked_sentence[i][1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
